{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7167f3c2",
   "metadata": {},
   "source": [
    "# Regression Problem - Predicting the Apparent Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38320441",
   "metadata": {},
   "source": [
    "*data leakage is going to be prevented by using a large amount of data (weather reports) in the train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237ba109",
   "metadata": {},
   "source": [
    "our dummy model - ?\n",
    "\n",
    "tommorow:\n",
    "\n",
    "## 3.random search, going over the models again\n",
    "\n",
    "1.visualization , understanding and improving, writing better documentation after.\n",
    "\n",
    "## 2.metrics - choosing mae/r2 , better understanding of the meaning\n",
    "check out AUC!\n",
    "\n",
    "4. catagorial features\n",
    "\n",
    "## 5. feature selection, new features \n",
    "\n",
    "6. summing up and trying to explain to myself about the project\n",
    "\n",
    "\n",
    "\n",
    "*** probability questions!\n",
    "*** in friday and saturday explaining to someone else!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3818cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e3d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84d45a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset \n",
    "weather =pd.read_csv(\"weatherHistory[1].csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13785ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6b3a95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df9613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change misprint\n",
    "weather=weather.rename(columns={'Loud Cover': 'Cloud Cover'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3c52b8",
   "metadata": {},
   "source": [
    "# 1. getting to know the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38324a4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fd82bd",
   "metadata": {},
   "source": [
    "### What are the features?\n",
    "*Formatted Date - includes day, week , month, year\n",
    "\n",
    "*Summary - sum up of the weather in words\n",
    "\n",
    "*Precip Type - which type of raindrops there are\n",
    "\n",
    "*Temperature (C) - temp in celcius\n",
    "\n",
    "*Humidity - Humidity depends on the temperature and pressure .\n",
    "\n",
    "*Wind Speed (km/h)\t\n",
    "\n",
    "*Wind Bearing (degrees)\t- direction of the wind in degrees. For example , a wind blowing from the north has a wind direction referred to as 0° (360°); a wind blowing from the east has a wind direction referred to as 90°, etc.\n",
    "<!-- The term \"wind direction\" is defined as the compass heading FROM which the wind is blowing -->\n",
    "\n",
    "*Visibility (km) - visibility is a measure of the distance at which an object or light can be clearly discerned.\t\n",
    "\n",
    "*Cloud Cover\t(loud cover- misprint)\n",
    "\n",
    "*Pressure (millibars) - High pressure means the air is heavy . Under high pressure you can generally expect sunny skies and calm weather , whereas Low pressure systems lead to active weather like wind and rain, and also severe weather.\n",
    "\n",
    "*Daily Summary - daily sum up of the weather in words\n",
    "\n",
    "\n",
    "## What is the target variable?\n",
    "\n",
    "Apparent Temperature : in simple words, Apparent Temperature is the temperature humans percieve, mostly outdoors, as a combination or the actual air temperature, humidity and wind. \n",
    "\n",
    "What else do we know?\n",
    "\n",
    "\n",
    "*we are starting with 12 variables (including the dependent)\n",
    "\n",
    "\n",
    "\n",
    "<!-- is The perceived temperature in degrees Fahrenheit derived from either a combination of temperature and wind (Wind Chill) or temperature and humidity (Heat Index) for the indicated hour. -\n",
    "->\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!-- 1. Because the response variable is continuous, this is a regression problem.\n",
    "2.There are 96453 observations (represented by the rows), and each observation is a weather report from a different date.\n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dad687",
   "metadata": {},
   "source": [
    "### the numeric variables histogramas:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462915ed",
   "metadata": {},
   "source": [
    "here we can see the distribution of the numeric features, and approximately understand the most frequent values of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3a3dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "atttibutes_hist = weather[[\"Temperature (C)\", \"Apparent Temperature (C)\", \"Wind Speed (km/h)\",\"Wind Bearing (degrees)\",'Visibility (km)', \"Pressure (millibars)\",'Cloud Cover']].hist(bins=50, figsize=(20,15))\n",
    "atttibutes_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ce7618",
   "metadata": {},
   "source": [
    "as we can see, cloud cover has only values of 0 , so we should delete it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6ec9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del weather['Cloud Cover']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f27c2a",
   "metadata": {},
   "source": [
    "# 2. preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9d058",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7a53f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22fd1ca",
   "metadata": {},
   "source": [
    "as we can see, there is still nan values in the Precip Type column, but the percentage of it is low.\n",
    "\n",
    "we will handle this by fill in the most common catagory of this feature (rain) instead of the nan values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30fea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weather['Precip Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4563cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "weather['Precip Type'] = weather['Precip Type'].fillna(\"rain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be4d79f",
   "metadata": {},
   "source": [
    "\n",
    "#### Precip Type, Temperature, wind speed , Wind Bearing, pressure are features that supposed to be  linked very strongly with the Apparent Temperature (according to the information we read), they are crucial for the prediction of the Apparent Temperature. \n",
    "\n",
    "on the other hand, daily summary is not that beneficial,  since we have the column Precip Type and also Summary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed19638",
   "metadata": {},
   "outputs": [],
   "source": [
    "del weather['Daily Summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896d511c",
   "metadata": {},
   "source": [
    "now , we will split the 'Formatted Date' feature to 4 different numeric attributes in order to get a better understanding of the data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2756cfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038cb71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['Formatted Date'] = pd.to_datetime(weather['Formatted Date'],utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a529a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['year'] = weather['Formatted Date'].dt.year\n",
    "weather['month'] = weather['Formatted Date'].dt.month\n",
    "weather['day'] = weather['Formatted Date'].dt.day\n",
    "weather['weekday'] = weather['Formatted Date'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972fecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "del weather['Formatted Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f42d124",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d222ea1",
   "metadata": {},
   "source": [
    "# getting rid of outliers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44023cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weather['Summary'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229f8840",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weather[(weather['Summary'] != \"Dangerously Windy and Partly Cloudy\") &( weather['Summary'] != \"Breezy and Dry\") & (weather['Summary']!=\"Windy and Dry\") ]\n",
    "print(weather['Summary'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248cedc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['Summary']=='Foggy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e7ecb7",
   "metadata": {},
   "source": [
    "### replacing a feature with a better one ??? בינתיים מחקתי את שני המשתנים שיצרתי middle of year ו wind- visibility  כי ראיתי שהם לא תורמים ממש לחיזוי , קורולציה סבירה אבל יש דברים אחרים שצריך לטפל שבהם כמו טיפול באינפיניטי "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fc4e82",
   "metadata": {},
   "source": [
    "# checking the relations between humidity and pressure, according to information we've read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2defc91",
   "metadata": {},
   "source": [
    "As humidity increases pressure decreases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc716b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "sns.regplot(data=weather, x=\"Apparent Temperature (C)\", y=\"Humidity\", color=\"g\")\n",
    "plt.title(\"Relation between Apparent Temperature (C) and Humidity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05e8ad4",
   "metadata": {},
   "source": [
    "There is a Linear Relation between “Apparent Temperature ” and “Humidity” with a negative slope. As air temperature increases, air can hold more water molecules, and its relative humidity decreases. When temperatures drop, relative humidity increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b88b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(weather, kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b68e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.boxplot(figsize=(18,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2046f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather['wind-visibility-ratio']=weather['Wind Speed (km/h)']/weather['Visibility (km)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965d0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# atttibutes_hist = weather[[\"Temperature (C)\",\"month\",'Humidity']].hist(bins=50, figsize=(20,15))\n",
    "# atttibutes_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569efca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sns.pairplot(weather, x_vars=['month'], y_vars='Apparent Temperature (C)', height=7, aspect=0.7, kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52ba94e",
   "metadata": {},
   "source": [
    "conclusion: when humidity is low, pressure is high"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc68b81",
   "metadata": {},
   "source": [
    "#### as we can see above, the Apparent Temperature  is higher in the months that are in the middle of the year.\n",
    "\n",
    "####  so, we can create a feature that checks if the month is in the middle of the year , or the beggining or the end - we will set the beggining of the middle to be the 5th month, and the end of the middle to be the 9th month\n",
    "\n",
    "#### this feature will be called: \"middle of year\" and will have yes/no values.\n",
    "\n",
    "#### this is a good idea to replace this feature with the \"month\" feature , since it's giving us a more intuitive relation with the Apparent Temperature, and it probably has a  stronger correlation to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caa95a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather['middle of year']=(weather['month']>5) & (weather['month']<9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4753891a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sns.pairplot(weather, x_vars=['middle of year'], y_vars='Apparent Temperature (C)', height=7, aspect=0.7, kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4c758c",
   "metadata": {},
   "source": [
    "as we can see in the correlation below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a290f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr_matrix = weather.corr()\n",
    "corr_matrix['Apparent Temperature (C)'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235f90af",
   "metadata": {},
   "source": [
    "## 1.2 encoding catagorial data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf19594c",
   "metadata": {},
   "source": [
    "we need to encode Summary, Precip Type and middle of year to numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf33962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i will save the original dataFrame for a later use, for example , for the data visualization.\n",
    "weather_copy=weather.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac2c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e76a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['Precip Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9460baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(weather['middle of year'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff03c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or \n",
    "print(weather['Precip Type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5cb65b",
   "metadata": {},
   "source": [
    "If a categorical column has just two categories (it's called a binary category), then we can replace their values with 0 and 1. and because the 'Precip Type' column has only 2 catagoreis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7743cc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_types = {'rain':0,'snow':1}\n",
    "weather['precip_type']= weather['Precip Type'].map(precip_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c9d581",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['precip_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4c8dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['Summary'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62db4e3",
   "metadata": {},
   "source": [
    "In contrast to the 'precip_type' column , the Summary column has a lot of catagories, so we will use labelEncoder in order to transform the non-numerical labels to numerical labels  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "lbl_encoder=preprocessing.LabelEncoder()\n",
    "weather['summary'] = lbl_encoder.fit_transform(weather['Summary'])\n",
    "weather['summary'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e37beb5",
   "metadata": {},
   "source": [
    "now, after we encoded these values, we need to handle another problem:\n",
    "the machine learning model may assume that there is some correlation between these variables, which will produce the wrong output. So to remove this issue, we will use dummy encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880e8195",
   "metadata": {},
   "source": [
    "For Dummy Encoding, we will use OneHotEncoder class of preprocessing library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500e9e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #for Country Variable  \n",
    "# from sklearn.preprocessing import LabelEncoder, OneHotEncoder  \n",
    "# label_encoder_x= LabelEncoder()  \n",
    "# weather['Precip Type']= label_encoder_x.fit_transform(weather['Precip Type'])  \n",
    "# #Encoding for dummy variables  \n",
    "# onehot_encoder= OneHotEncoder(categories=weather['Precip Type'])    \n",
    "\n",
    "\n",
    "# pre= onehot_encoder.fit_transform(pre).toarray()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705436a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy encoding of categorical features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8da2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(weather[['summary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce612f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c67846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(weather[['precip_type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0517b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['precip_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f91ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ohe.fit_transform(weather[['middle of year']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather['middle of year']=weather['middle of year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dceaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(weather[['precip_type']]==1.).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23f926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700f6033",
   "metadata": {},
   "source": [
    "## 1.3 doing onehotencoding at the same time on both of the categorial columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8709de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather['middle of year']=pd.get_dummies(weather['middle of year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744ea2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use when different features need different preprocessing\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805b2565",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans = make_column_transformer(\n",
    "    (OneHotEncoder(), ['Summary']),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab2a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=column_trans.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8399077",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90680647",
   "metadata": {},
   "source": [
    "now, we will remove Summary and Precip Type columns, cause we alredy made the numeric version of them(summary,precip_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d8de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "del weather['Summary']\n",
    "del weather['Precip Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4b0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data={'features': weather.columns})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea8a2af",
   "metadata": {},
   "source": [
    "# 3. data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eea100",
   "metadata": {},
   "source": [
    " using the preproccessed dataFrame, before scaling, \n",
    "in order to get meaningful and clear picture of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97cda03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# weather.plot(x='Apparent Temperature (C)', y=[\"precip_type\"])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04001f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AT_column = weather['Apparent Temperature (C)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdafd20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AT_column.plot(kind=\"hist\")\n",
    "AxesSubplot='Frequency'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4d4f56",
   "metadata": {},
   "source": [
    "##### this means that the most frequent Apparent Temperature is in the range between 10 to 20 celcius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b852ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f861a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import plotly.express as px\n",
    "# %matplotlib inline\n",
    "\n",
    "# fig , axs = plt.subplots(ncols=7,nrows=2, figsize=(20,10))\n",
    "\n",
    "# for k ,v in weather.items():\n",
    "#     sns.boxplot(y=k, data=weather, ax=axs[index])\n",
    "#     index +=1\n",
    "# plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc613f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=weather['Apparent Temperature (C)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e804978",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , axs = plt.subplots(ncols=7,nrows=2, figsize=(20,10))\n",
    "index=0\n",
    "axs= axs.flatten()\n",
    "for k ,v in weather.items():\n",
    "    sns.boxplot(y=k, data=weather , ax=axs[index])\n",
    "    index +=1\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5603ed",
   "metadata": {},
   "source": [
    "*temperature ,apparant temperature and humidity features has outliers after the min, but not a lot\n",
    "\n",
    "*wind speed and summary - a lot of outliers , varies less and therefore, easier to predict\n",
    "\n",
    "*most of  the values of wind bearing and visibility features are in the top 50% - the higher values , in contrast to apparant temperature and humidity.\n",
    "\n",
    "*middle of year and precif type doesn't have a median "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f4f331",
   "metadata": {},
   "source": [
    "# correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3004e893",
   "metadata": {},
   "source": [
    "### correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2de941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather['wind-visibility-ratio']=weather['Wind Speed (km/h)']/weather['Visibility (km)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025bed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather.describe()[['humidity-wind-ratio', 'wind-visibility-ratio','Visibility (km)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9bff10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(weather.corr(),annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac9b1c8",
   "metadata": {},
   "source": [
    "as we can see from the heatmap above, the correlation between the Apparent Temperature to the pressure is very low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6d0c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del weather['Pressure (millibars)']\n",
    "del weather['weekday']\n",
    "del weather['day']\n",
    "del weather['year']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa08fbc5",
   "metadata": {},
   "source": [
    "# numerical  features correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f740ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize the relationship between the features and the response using scatterplots\n",
    "sns.pairplot(weather, x_vars=['Temperature (C)','Humidity','Wind Speed (km/h)','Wind Bearing (degrees)','Visibility (km)'], y_vars='Apparent Temperature (C)', height=7, aspect=0.7, kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=weather, x='Visibility (km)', y=\"Wind Speed (km/h)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d3446c",
   "metadata": {},
   "source": [
    "*we can see clearly that there's a strong correlation between temperature and apparent temperatue, \n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42079275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns; #sns.set_theme(color_codes=True)\n",
    "ax = sns.regplot(x='Wind Speed (km/h)', y=\"Apparent Temperature (C)\", data=weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68021a0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.set_theme(style=\"whitegrid\")\n",
    "# ax = sns.boxplot(x=\"Visibility (km)\", y=\"Wind Speed (km/h)\", data=weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620f36c7",
   "metadata": {},
   "source": [
    "# categorial features correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dcf16a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weather_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507e02d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weatheבםפט['Summary'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5282d775",
   "metadata": {},
   "source": [
    "we took samples of catagories from the \"Summary\" feature, in order to see the relations between this feature and the \"Precip Type\" feature with Wind Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dcce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "ax = sns.stripplot(x=\"Summary\", y='Apparent Temperature (C)',hue='Precip Type',order=['Rain','Partly Cloudy','Overcast','Foggy','Breezy'], data=weather_copy , linewidth= 1, size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a57344",
   "metadata": {},
   "source": [
    "*here we can see what we think intuitively - the apparent temperature, i.e., the temperature we as humans feel is higher when there's snow comparing to when it rains. \n",
    "\n",
    "*We assumed that if there's an overcast, the apparent temperatue is lower, but here we can see that it's not neccesarily the case, so we can't say there's a strong correlation between the overcast catagory in Summary and the apparent temperatue.\n",
    "\n",
    "*another thing we see here is that when it rains, the apparent temperature can vary from 0 to 40 approximately, which means that it's hard to predict what temperature  we would feel when the precip type is rain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec363dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d63b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "ax = sns.stripplot(x=\"Summary\", y=\"Wind Speed (km/h)\",hue='Precip Type',order=['Rain','Partly Cloudy','Overcast','Foggy','Breezy','Dry'], data=weather_copy , linewidth= 1, size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645722b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "# fig.suptitle('categorial features:')\n",
    "# ax = sns.swarmplot(x=weather_copy[\"Summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca47367",
   "metadata": {},
   "source": [
    "now let's see the correlation between the features after the few changes we did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3ae1e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_matrix = weather.corr()\n",
    "corr_matrix['Apparent Temperature (C)'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baf9981",
   "metadata": {},
   "source": [
    "# 4. choosing a regression metric -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a9dca4",
   "metadata": {},
   "source": [
    "### We chose Mean abs error and R square as  metrics due to the explanations below and also beacause of the following dummy model results   (mae had a better result than rmse)\n",
    "### later on we will choose one of them as a metric to our best model for the data, depending on how well it works with each model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8621df5e",
   "metadata": {},
   "source": [
    "##### Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032ec1bf",
   "metadata": {},
   "source": [
    "The MSE is calculated as the mean or average of the squared differences between predicted and expected target values in a dataset\n",
    "\n",
    "when MSE is used as a loss function (regression metric), a lot of weight is given to larger errors because of the square\n",
    "The units of the MSE are squared units.\n",
    "\n",
    "A model that achieves an MSE better than the MSE for the naive model has skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9c92dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db6ec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of calculate the mean squared error\n",
    "# real value\n",
    "expected = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "# predicted value\n",
    "predicted = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.0]\n",
    "# calculate errors\n",
    "errors = mean_squared_error(expected, predicted)\n",
    "# report error\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81127412",
   "metadata": {},
   "source": [
    "##### Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f3a74c",
   "metadata": {},
   "source": [
    "the units of the RMSE are the same as the original units of the target value that is being predicted, in contrast to MSE.\n",
    "this is the advantage comapring to MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b11ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_true, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a9815e",
   "metadata": {},
   "source": [
    "#### Mean abs error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b109bdf1",
   "metadata": {},
   "source": [
    "like RMSE, the units of the error score match the units of the target value that is being predicted.\n",
    "\n",
    "Unlike the RMSE, the changes in MAE are linear and therefore intuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f008be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of calculate the mean absolute error\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# # real value\n",
    "# expected = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "# # predicted value\n",
    "# predicted = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.0]\n",
    "# # calculate errors\n",
    "# errors = mean_absolute_error(expected, predicted)\n",
    "# # report error\n",
    "# print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db47b11",
   "metadata": {},
   "source": [
    "*The lower value of MAE, MSE, and RMSE implies higher accuracy of a regression model. However, a higher value of R square is considered desirable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b849a",
   "metadata": {},
   "source": [
    "#### R Square"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d15049",
   "metadata": {},
   "source": [
    "R Squared & Adjusted R Squared are used for explaining how well the independent variables in the linear regression model explains the variability in the dependent variable.\n",
    "\n",
    "R-squared (R2) is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e71ba03",
   "metadata": {},
   "source": [
    "# 5. Split the data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791723b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = weather.drop(['Apparent Temperature (C)'],axis=1)\n",
    "y = weather['Apparent Temperature (C)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a382909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd6a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train=X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d98e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c84cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81325a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dccd8c6",
   "metadata": {},
   "source": [
    "## Scaling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76879f22",
   "metadata": {},
   "source": [
    "את הנירמול לא נעשה על משתנים קטגרויאליים ושמיים שעשינו עליהם כבר encoding  \n",
    ",כי אין אפשרות להשוות\n",
    "ניצור גאטא פריים חדש מנורמל\n",
    "את הויזואליצזיה של הדאטא נעשה על הדאטא פריים המקורי, הלא מנורמל, כדי שנראה את המידע בצורה ברורה ונראה מה המספרים מייצגים"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9636f0a5",
   "metadata": {},
   "source": [
    "we will do the scaling only on numerical features i.e not on the categorial . \n",
    " i.e , the features we didn't encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d95db0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.head()\n",
    "# delete presure , day month weekday ...\n",
    "#percip type and summary are catagorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2048347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4da1724",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_standard = StandardScaler()\n",
    "scaler_MinMax = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14740b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_standardized = X_train.copy()\n",
    "X_test_standardized = X_test.copy()\n",
    "X_train_normalized = X_train.copy()\n",
    "X_test_normalized = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f664a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [\"Temperature (C)\",\"Humidity\",\"Wind Speed (km/h)\",\"Wind Bearing (degrees)\",\"Visibility (km)\",\"Pressure (millibars)\",\"month\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2741d90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization:\n",
    "scaler_standard.fit(X_train[numerical_features])\n",
    "X_train_standardized[numerical_features] = scaler_standard.transform(X_train_standardized[numerical_features])\n",
    "\n",
    "# the scaling is with the the same fitted scaler (by the train data)\n",
    "#only transform on the test data\n",
    "X_test_standardized[numerical_features] = scaler_standard.transform(X_test_standardized[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833de946",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('note: the mean is 0 and std is 1')\n",
    "X_train_standardized.describe()[numerical_features].iloc[[1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce6ca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization:\n",
    "scaler_MinMax.fit(X_train[numerical_features])\n",
    "X_train_normalized[numerical_features] = scaler_MinMax.transform(X_train_normalized[numerical_features])\n",
    "\n",
    "# the scaling is with the the same fitted scaler (by the train data)\n",
    "#only transform on the test data\n",
    "X_test_normalized[numerical_features] = scaler_MinMax.transform(X_test_normalized[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65643176",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('note: the mean is 0 and std is 1')\n",
    "X_train_standardized.describe()[numerical_features].iloc[[1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789db6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scale=X_train.copy()\n",
    "y_train_scale=y_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f7d4b4",
   "metadata": {},
   "source": [
    "deleting the encoded variables (categorials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cb6ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X_train_scale['summary']\n",
    "# del X_train_scale['precip_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dbaa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb5e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling= MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070122ef",
   "metadata": {},
   "source": [
    "*on the train set -fit and transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a271b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scaling.fit_transform(X_train_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a245d60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arr_y_train=np.array(y_train_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ef504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling.fit_transform(arr_y_train.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70d4c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arr_x_test=np.array(X_train_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c647d0a",
   "metadata": {},
   "source": [
    "*on the test set -transform only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2f967d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scaling.transform(arr_x_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7d4b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arr_y_test=np.array(y_train_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eca243",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scaling.transform(arr_y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa1315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(index=range(len(train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e4e705",
   "metadata": {},
   "source": [
    "## dealing with imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5806a2",
   "metadata": {},
   "source": [
    "*** in this part we do not touch the test set!\n",
    " \n",
    " \n",
    " we will only use the test set for the dummy model , and after the cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c2c479",
   "metadata": {},
   "source": [
    "the data is imbalanced as we can see from the histogram below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53077ba3",
   "metadata": {},
   "source": [
    "## dummy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceed314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569cce37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dummy_regr = DummyRegressor(strategy=\"mean\")\n",
    "dummy_regr.fit(X_train, y_train)\n",
    "R2_score = dummy_regr.score(X_test, y_test)\n",
    "y_predict = dummy_regr.predict(X_test)\n",
    "mae = MAE(y_test, y_predict)\n",
    "rmse= mean_squared_error(y_test, y_predict, squared=False)\n",
    "\n",
    "\n",
    "print ('The dummy model have a root mean squared error of '+ str(rmse) )\n",
    "\n",
    "# errorsRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b77b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('The dummy model have a R2 score of ' + str(R2_score)[:6] + \" as expected (around 0), and mean absolute error of \" + str(mae)[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38ffab2",
   "metadata": {},
   "source": [
    "# The dummy model have a R2 score of -7.151 as expected (around 0), and mean absolute error of 9.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cddfb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_regr = DummyRegressor(strategy=\"mean\")\n",
    "# dummy_regr.fit(X_train, y_train)\n",
    "# dummy_regr.predict(X_train, y_train)\n",
    "# dummy_regr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a98f23b",
   "metadata": {},
   "source": [
    "# comparing different Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f52b4c8",
   "metadata": {},
   "source": [
    "*cross validation allows us to compare different machine learning methods and get a sense of how well they will work in practice. the advantage here, is that it uses different blocks of data for train and test, and by that, \"prepare\" the model in the best way to predict outcome for new data  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bf366d",
   "metadata": {},
   "source": [
    " # Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72d6be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe4b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144591f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be16941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4604b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "R2_scores_standardized = cross_val_score(LR, X_train_standardized, y_train, cv=kf)\n",
    "y_predict_standardized = cross_val_predict(LR, X_train_standardized, y_train, cv=kf)\n",
    "mae_standarsized = MAE(y_train, y_predict_standardized)\n",
    "\n",
    "R2_scores_normalized = cross_val_score(LR, X_train_normalized, y_train, cv=kf)\n",
    "y_predict_normalized = cross_val_predict(LR, X_train_normalized, y_train, cv=kf)\n",
    "mae_normalized = MAE(y_train, y_predict_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bde279",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2)\n",
    "((ax1, ax2)) = axes\n",
    "\n",
    "y_predicted = cross_val_predict(LR, X_train_standardized, y_train, cv=kf)\n",
    "ax1.scatter(y_train, y_predicted, alpha=0.3, color='orange')\n",
    "ax1.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k--', lw=4)\n",
    "ax1.set_xlabel('Actual')\n",
    "ax1.set_ylabel('Predicted')\n",
    "ax1.set_title('standardized:')\n",
    "\n",
    "y_predicted = cross_val_predict(LR, X_train_normalized, y_train, cv=kf)\n",
    "ax2.scatter(y_train, y_predicted, alpha=0.3, color='red')\n",
    "ax2.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k--', lw=4)\n",
    "ax2.set_xlabel('Actual')\n",
    "ax2.set_ylabel('Predicted')\n",
    "ax2.set_title('normalized:')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabb72a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standadized train set cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6bbc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the scores of cross validation are:\")\n",
    "print(R2_scores_standardized)\n",
    "print()\n",
    "print(\"mean R2 is: \" + str(R2_scores_standardized.mean())[:5] + \" with std of  \" + str(R2_scores_standardized.std())[:5] + \" and MAE of \" + str(mae_standarsized)[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c92f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalized train set cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20454da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the scores of cross validation are:\")\n",
    "print(R2_scores_normalized)\n",
    "print()\n",
    "print(\"mean R2 is: \" + str(R2_scores_normalized.mean())[:5] + \" with std of  \" + str(R2_scores_normalized.std())[:5] + \" and MAE of \" + str(mae_normalized)[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d17fa3e",
   "metadata": {},
   "source": [
    "although the results are the same with normalized and standardized,\n",
    "we can see below that the feature values are definetly different "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8510b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffdcb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210aa93b",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb1c66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd3d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5850f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0653504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_scores_standardized = cross_val_score(regr, X_train_standardized, y_train, cv=kf)\n",
    "y_predict_standardized = cross_val_predict(regr, X_train_standardized, y_train, cv=kf)\n",
    "mae_standarsized = MAE(y_train, y_predict_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d53635",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_scores_normalized = cross_val_score(regr, X_train_normalized, y_train, cv=kf)\n",
    "y_predict_normalized = cross_val_predict(regr, X_train_normalized, y_train, cv=kf)\n",
    "mae_normalized = MAE(y_train, y_predict_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64f5ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the scores of cross validation are:\")\n",
    "print(R2_scores_standardized)\n",
    "print()\n",
    "print(\"mean R2 is: \" + str(R2_scores_standardized.mean())[:5] + \" with std of  \" + str(R2_scores_standardized.std())[:5] + \" and MAE of \" + str(mae_standarsized)[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45edf5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the scores of cross validation are:\")\n",
    "print(R2_scores_normalized)\n",
    "print()\n",
    "print(\"mean R2 is: \" + str(R2_scores_normalized.mean())[:5] + \" with std of  \" + str(R2_scores_normalized.std())[:5] + \" and MAE of \" + str(mae_normalized)[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caa631c",
   "metadata": {},
   "source": [
    "the results are not so good with the MAE metric. we will try to decrese the MAE and increase the R2 with random search - choosing the best hyperparameter for the random forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeceeb3",
   "metadata": {},
   "source": [
    "# random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab1dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838c514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ae71e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search across 100 different combinations\n",
    "rf_random = RandomizedSearchCV(estimator = RFR, param_distributions = random_grid, n_iter = 100, cv = kf, verbose=2, random_state=42, n_jobs = -1, scoring='r2')\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train_normalized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a19275",
   "metadata": {},
   "source": [
    "# Random Forest Regressor standardized data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fd4864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80c05ef6",
   "metadata": {},
   "source": [
    "# Keras Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa52a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaec45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9564c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc16f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121e0ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3bf43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Also, ADAM optimization algorithm is used for optimizing loss function (Mean squared error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d8e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.metrics.RootMeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43055502",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(11,activation='relu'))\n",
    "model.add(Dense(11,activation='relu'))\n",
    "model.add(Dense(11,activation='relu'))\n",
    "model.add(Dense(11,activation='relu'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae',tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad80418",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4828a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train).astype(np.float32)\n",
    "y_train = np.asarray(y_train).astype(np.float32)\n",
    "X_test= np.asarray(X_test).astype(np.float32)\n",
    "y_test= np.asarray(y_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d42dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=X_train,y=y_train,\n",
    "          validation_data=(X_test,y_test),\n",
    "          batch_size=128,epochs=400)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae377c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac264e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history.history['val_mse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24053a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history.history['val_mae']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8568f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history.history['val_root_mean_squared_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a188ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot metrics\n",
    "pyplot.plot(loss_df ['mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0418216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(loss_df ['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b11c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(loss_df ['root_mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26308a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(loss_df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52955c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab97ac4e",
   "metadata": {},
   "source": [
    "# hyperparameter tuning \n",
    "I will try to increase the R2 score and the MAE of the Random Forest Regressor model by choosing the best hyperparams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e88e9c",
   "metadata": {},
   "source": [
    "## random search "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7349785",
   "metadata": {},
   "source": [
    "With small data sets and lots of resources, Grid Search will produce accurate results. However, with large data sets, the high dimensions will greatly slow down computation time and be very costly. Therefore, we chose to use random search for "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08897bf2",
   "metadata": {},
   "source": [
    "random search requires two arguments. The first is the model that you are optimizing. This is an instance of the model with values of hyperparameters set that you want to optimize. \n",
    "The second is the search space:\n",
    "This is defined as a dictionary where the names are the hyperparameter arguments to the model and the values are discrete values or a distribution of values to sample in the case of a random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611fdee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.stats import loguniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f260271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28c5041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Ridge()\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['svd', 'cholesky', 'lsqr', 'sag']\n",
    "space['alpha'] = loguniform(1e-5, 100)\n",
    "space['fit_intercept'] = [True, False]\n",
    "space['normalize'] = [True, False]\n",
    "\n",
    "# define search\n",
    "# pattern - search = GridSearchCV(model, space)\n",
    "search = RandomizedSearchCV(model, space, n_iter=500, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7197d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute search\n",
    "result = search.fit(X_train_normalized, y_train)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c907da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3caac216",
   "metadata": {},
   "source": [
    "For Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e744560c",
   "metadata": {},
   "source": [
    "what can we do better?\n",
    "\n",
    "*use SMOGN or SMOTER to balance the data\n",
    "*use other feature selection methods such as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5d687c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
