{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7167f3c2",
   "metadata": {},
   "source": [
    "# Regression Problem - Predicting the Apparent Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38320441",
   "metadata": {},
   "source": [
    "*data leakage is going to be prevented by using a large amount of data (weather reports) in the train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237ba109",
   "metadata": {},
   "source": [
    "our dummy model - ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3818cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305cc350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84d45a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset \n",
    "weather =pd.read_csv(\"weatherHistory[1].csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13785ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b708f04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df9613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change misprint\n",
    "weather=weather.rename(columns={'Loud Cover': 'Cloud Cover'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3c52b8",
   "metadata": {},
   "source": [
    "# 1. getting to know the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38324a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dad687",
   "metadata": {},
   "source": [
    "### the numeric variables histogramas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3a3dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "atttibutes_hist = weather[[\"Temperature (C)\", \"Apparent Temperature (C)\", \"Wind Speed (km/h)\", \"Pressure (millibars)\",'Cloud Cover']].hist(bins=50, figsize=(20,15))\n",
    "atttibutes_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ce7618",
   "metadata": {},
   "source": [
    "as we can see, cloud cover has only values of 0 , so we should delete it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6ec9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del weather['Cloud Cover']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0eb50f",
   "metadata": {},
   "source": [
    "### What are the features?\n",
    "*Formatted Date - includes day, week , month, year\n",
    "\n",
    "*Summary - sum up of the weather\n",
    "\n",
    "*Precip Type - which type of raindrops \n",
    "\n",
    "*Temperature (C)\n",
    "\n",
    "*Humidity - Humidity depends on the temperature and pressure .\n",
    "\n",
    "*Wind Speed (km/h)\t\n",
    "\n",
    "*Wind Bearing (degrees)\t- direction of the wind\n",
    "\n",
    "*Visibility (km) - visibility is a measure of the distance at which an object or light can be clearly discerned.\t\n",
    "\n",
    "*Cloud Cover\t(loud cover- misprint)\n",
    "\n",
    "*Pressure (millibars) - High pressure means the air is heavy . Under high pressure you can generally expect sunny skies and calm weather , whereas Low pressure systems lead to active weather like wind and rain, and also severe weather.\n",
    "\n",
    "*Daily Summary - daily sum up of the weather\n",
    "\n",
    "\n",
    "## What is the target variable?\n",
    "\n",
    "Apparent Temperature : in simple words, Apparent Temperature is the temperature humans percieve, mostly outdoors, as a combination or the actual air temperature, humidity and wind. \n",
    "\n",
    "What else do we know?\n",
    "\n",
    "\n",
    "*we are starting with 12 variables (including the dependent)\n",
    "\n",
    "\n",
    "\n",
    "<!-- is The perceived temperature in degrees Fahrenheit derived from either a combination of temperature and wind (Wind Chill) or temperature and humidity (Heat Index) for the indicated hour. -\n",
    "->\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!-- 1. Because the response variable is continuous, this is a regression problem.\n",
    "2.There are 96453 observations (represented by the rows), and each observation is a weather report from a different date.\n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f27c2a",
   "metadata": {},
   "source": [
    "# 2. preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9d058",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7a53f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22fd1ca",
   "metadata": {},
   "source": [
    "as we can see, there is still nan values in the Precip Type column.\n",
    "\n",
    "we will handle this by fill in the most common catagory of this feature (rain) instead of the nan values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30fea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weather['Precip Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4563cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "weather['Precip Type'] = weather['Precip Type'].fillna(\"rain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be4d79f",
   "metadata": {},
   "source": [
    "\n",
    "#### Precip Type, Temperature, wind speed , Wind Bearing, pressure are features that supposed to be  linked very strongly with the Apparent Temperature (according to the information we read), they are crucial for the prediction of the Apparent Temperature. \n",
    "\n",
    "on the other hand, daily summary is not that beneficial,  since we have the column Precip Type and also Summary.\n",
    "\n",
    "*The term \"wind direction\" is defined as the compass heading FROM which the wind is blowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed19638",
   "metadata": {},
   "outputs": [],
   "source": [
    "del weather['Daily Summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8457b61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896d511c",
   "metadata": {},
   "source": [
    "now , we will split the 'Formatted Date' feature to 4 different numeric attributes in order to get a better understanding of the data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2756cfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038cb71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['Formatted Date'] = pd.to_datetime(weather['Formatted Date'],utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a529a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['year'] = weather['Formatted Date'].dt.year\n",
    "weather['month'] = weather['Formatted Date'].dt.month\n",
    "weather['day'] = weather['Formatted Date'].dt.day\n",
    "weather['weekday'] = weather['Formatted Date'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972fecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "del weather['Formatted Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f42d124",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e39259",
   "metadata": {},
   "source": [
    "# checking the relations between humidity and pressure, according to information we've read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a14152",
   "metadata": {},
   "source": [
    "As humidity increases pressure decreases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b228ced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[['Apparent Temperature (C)','Humidity','Visibility (km)','Wind Speed (km/h)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d222ea1",
   "metadata": {},
   "source": [
    "getting rid of outliers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44023cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weather['Summary'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229f8840",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weather[(weather['Summary'] != \"Dangerously Windy and Partly Cloudy\") &( weather['Summary'] != \"Breezy and Dry\") & (weather['Summary']!=\"Windy and Dry\") ]\n",
    "print(weather['Summary'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248cedc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['Summary']=='Foggy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e7ecb7",
   "metadata": {},
   "source": [
    "### replacing a feature with a better one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e01f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "atttibutes_hist = weather[[\"Temperature (C)\",\"month\",'Humidity']].hist(bins=50, figsize=(20,15))\n",
    "atttibutes_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569efca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(weather, x_vars=['month'], y_vars='Apparent Temperature (C)', height=7, aspect=0.7, kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db41399",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(weather['Humidity'], weather['Visibility (km)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce961284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set_theme(color_codes=True)\n",
    "ax = sns.regplot(x='Humidity', y=\"Pressure (millibars)\", data=weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6202e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Pressure (millibars)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba97a22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plt.plot(weather['Pressure (millibars)'], weather['Apparent Temperature (C)'])#, 'b') # 'b' is for blue color -- Shift+Tab for more options\n",
    "# We can add labels and title\n",
    "# plt.xlabel('X Axis Title')\n",
    "# plt.ylabel('Y Axis Title')\n",
    "# plt.title('Figure/plot Title')\n",
    "#plt.scatter(weather['Pressure (millibars)'], weather['Humidity'])\n",
    "sns.pairplot(weather, x_vars='Wind Speed (km/h)', y_vars='Visibility (km)', height=7, aspect=0.7, kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b99a50",
   "metadata": {},
   "source": [
    "conclusion: when humidity is low, pressure is high"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc68b81",
   "metadata": {},
   "source": [
    "#### as we can see above, the Apparent Temperature  is higher in the months that are in the middle of the year.\n",
    "\n",
    "####  so, we can create a feature that checks if the month is in the middle of the year , or the beggining or the end - we will set the beggining of the middle to be the 5th month, and the end of the middle to be the 9th month\n",
    "\n",
    "#### this feature will be called: \"middle of year\" and will have yes/no values.\n",
    "\n",
    "#### this is a good idea to replace this feature with the \"month\" feature , since it's giving us a more intuitive relation with the Apparent Temperature, and it probably has a  stronger correlation to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caa95a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['middle of year']=(weather['month']>5) & (weather['month']<9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4753891a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(weather, x_vars=['middle of year'], y_vars='Apparent Temperature (C)', height=7, aspect=0.7, kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4c758c",
   "metadata": {},
   "source": [
    "as we can see in the correlation below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a290f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_matrix = weather.corr()\n",
    "corr_matrix['Apparent Temperature (C)'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235f90af",
   "metadata": {},
   "source": [
    "## 1.2 encoding catagorial data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf19594c",
   "metadata": {},
   "source": [
    "we need to encode Summary, Precip Type and middle of year to numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e3c0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i will save the original dataFrame for a later use, for example , for the data visualization.\n",
    "weather_copy=weather.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e76a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['Precip Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9460baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weather['middle of year'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff03c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or \n",
    "print(weather['Precip Type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5cb65b",
   "metadata": {},
   "source": [
    "If a categorical column has just two categories (it's called a binary category), then we can replace their values with 0 and 1. and because the 'Precip Type' column has only 2 catagoreis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7743cc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_types = {'rain':0,'snow':1}\n",
    "weather['precip_type']= weather['Precip Type'].map(precip_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242fd7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['precip_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4c8dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['Summary'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62db4e3",
   "metadata": {},
   "source": [
    "In contrast to the 'precip_type' column , the Summary column has a lot of catagories, so we will use labelEncoder in order to transform the non-numerical labels to numerical labels  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "lbl_encoder=preprocessing.LabelEncoder()\n",
    "weather['summary'] = lbl_encoder.fit_transform(weather['Summary'])\n",
    "weather['summary'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e37beb5",
   "metadata": {},
   "source": [
    "now, after we encoded these values, we need to handle another problem:\n",
    "the machine learning model may assume that there is some correlation between these variables, which will produce the wrong output. So to remove this issue, we will use dummy encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880e8195",
   "metadata": {},
   "source": [
    "For Dummy Encoding, we will use OneHotEncoder class of preprocessing library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500e9e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #for Country Variable  \n",
    "# from sklearn.preprocessing import LabelEncoder, OneHotEncoder  \n",
    "# label_encoder_x= LabelEncoder()  \n",
    "# weather['Precip Type']= label_encoder_x.fit_transform(weather['Precip Type'])  \n",
    "# #Encoding for dummy variables  \n",
    "# onehot_encoder= OneHotEncoder(categories=weather['Precip Type'])    \n",
    "\n",
    "\n",
    "# pre= onehot_encoder.fit_transform(pre).toarray()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705436a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy encoding of categorical features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8da2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(weather[['summary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce612f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c67846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(weather[['precip_type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137b64e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['precip_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f91ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(weather[['middle of year']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4df4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['middle of year']=weather['middle of year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dceaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(weather[['precip_type']]==1.).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e25a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700f6033",
   "metadata": {},
   "source": [
    "## 1.3 doing onehotencoding at the same time on both of the categorial columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43535fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X= weather_copy.loc[:, ['Summary','middle of year'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a2665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f6dc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['middle of year']=pd.get_dummies(weather['middle of year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744ea2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use when different features need different preprocessing\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805b2565",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans = make_column_transformer(\n",
    "    (OneHotEncoder(), ['Summary','middle of year']),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab2a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=column_trans.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94c6d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90680647",
   "metadata": {},
   "source": [
    "now, we will remove Summary and Precip Type columns, cause we alredy made the numeric version of them(summary,precip_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d8de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "del weather['Summary']\n",
    "del weather['Precip Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5d8b2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4b0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data={'features': weather.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1412a17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea8a2af",
   "metadata": {},
   "source": [
    "# 3. data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eea100",
   "metadata": {},
   "source": [
    " using the preproccessed dataFrame, before scaling, \n",
    "in order to get meaningful and clear picture of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97cda03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# weather.plot(x='Apparent Temperature (C)', y=[\"precip_type\"])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04001f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AT_column = weather['Apparent Temperature (C)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdafd20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AT_column.plot(kind=\"hist\")\n",
    "AxesSubplot='Frequency'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4d4f56",
   "metadata": {},
   "source": [
    "##### this means that the most frequent Apparent Temperature is in the range between 10 to 20 celcius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b852ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import plotly.express as px\n",
    "# %matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f861a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import plotly.express as px\n",
    "# %matplotlib inline\n",
    "\n",
    "# fig , axs = plt.subplots(ncols=7,nrows=2, figsize=(20,10))\n",
    "# index=0\n",
    "# axs= axs.flatten()\n",
    "# for k ,v in weather.items():\n",
    "#     sns.boxplot(y=k, data=weather , ax=axs[index])\n",
    "#     index +=1\n",
    "# plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e804978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig , axs = plt.subplots(ncols=7,nrows=2, figsize=(20,10))\n",
    "# index=0\n",
    "# axs= axs.flatten()\n",
    "# for k ,v in weather.items():\n",
    "#     sns.boxplot(y=k, data=weather , ax=axs[index])\n",
    "#     index +=1\n",
    "# plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f4f331",
   "metadata": {},
   "source": [
    "# correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3004e893",
   "metadata": {},
   "source": [
    "### correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e54a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather['pressure-humidity-ratio']=weather['Humidity']/weather['Pressure (millibars)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057b3995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#weather['pressure-humidity-ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5910551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather['humidity-wind-ratio']=weather['Wind Speed (km/h)']/weather['Humidity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a45423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['wind-visibility-ratio']=weather['Wind Speed (km/h)']/weather['Visibility (km)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97224fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather.describe()[['humidity-wind-ratio', 'wind-visibility-ratio','Visibility (km)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9bff10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(weather.corr(),annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29de174",
   "metadata": {},
   "source": [
    "as we can see from the heatmap above, the correlation between the Apparent Temperature to the pressure is very low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6d0c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del weather['Pressure (millibars)']\n",
    "del weather['weekday']\n",
    "del weather['day']\n",
    "del weather['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39971c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical  features correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f740ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize the relationship between the features and the response using scatterplots\n",
    "sns.pairplot(weather, x_vars=['Temperature (C)','Humidity','Wind Speed (km/h)','Wind Bearing (degrees)','Visibility (km)'], y_vars='Apparent Temperature (C)', height=7, aspect=0.7, kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feee714a",
   "metadata": {},
   "source": [
    "# categorial features correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3615433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_copy['middle of year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e8fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "fig.suptitle('categorial features:')\n",
    "\n",
    "sns.swarmplot(ax=axes[0,0], x=\"Temperature (C)\", y=\"Apparent Temperature (C)\", data=weather_copy)\n",
    "sns.swarmplot(ax=axes[0,1], x=\"Humidity\", y=\"Apparent Temperature (C)\", data=weather_copy)\n",
    "sns.swarmplot(ax=axes[1,0], x=\"Wind Speed (km/h)\", y=\"Apparent Temperature (C)\", data=weather_copy)\n",
    "sns.swarmplot(ax=axes[1,1], x=\"Wind Bearing (degrees)\", y=\"Apparent Temperature (C)s\", data=weather_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baf9981",
   "metadata": {},
   "source": [
    "# 4. choosing a regression metric -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb47f16",
   "metadata": {},
   "source": [
    "### We chose Mean abs error as a metric due to the explanations below and also beacause of the following dummy model results   (mae had a better result than rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8621df5e",
   "metadata": {},
   "source": [
    "##### Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549c57a7",
   "metadata": {},
   "source": [
    "The MSE is calculated as the mean or average of the squared differences between predicted and expected target values in a dataset\n",
    "\n",
    "when MSE is used as a loss function (regression metric), a lot of weight is given to larger errors because of the square\n",
    "The units of the MSE are squared units.\n",
    "\n",
    "A model that achieves an MSE better than the MSE for the naive model has skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9c92dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db6ec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of calculate the mean squared error\n",
    "# real value\n",
    "expected = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "# predicted value\n",
    "predicted = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.0]\n",
    "# calculate errors\n",
    "errors = mean_squared_error(expected, predicted)\n",
    "# report error\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81127412",
   "metadata": {},
   "source": [
    "##### Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959bba06",
   "metadata": {},
   "source": [
    "the units of the RMSE are the same as the original units of the target value that is being predicted, in contrast to MSE.\n",
    "this is the advantage comapring to MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cc63e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_true, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a9815e",
   "metadata": {},
   "source": [
    "#### Mean abs error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab879907",
   "metadata": {},
   "source": [
    "like RMSE, the units of the error score match the units of the target value that is being predicted.\n",
    "\n",
    "Unlike the RMSE, the changes in MAE are linear and therefore intuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f008be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of calculate the mean absolute error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# real value\n",
    "expected = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "# predicted value\n",
    "predicted = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.0]\n",
    "# calculate errors\n",
    "errors = mean_absolute_error(expected, predicted)\n",
    "# report error\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f2fed5",
   "metadata": {},
   "source": [
    "*The lower value of MAE, MSE, and RMSE implies higher accuracy of a regression model. However, a higher value of R square is considered desirable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaef132",
   "metadata": {},
   "outputs": [],
   "source": [
    "R Square"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40634a33",
   "metadata": {},
   "source": [
    "R Squared & Adjusted R Squared are used for explaining how well the independent variables in the linear regression model explains the variability in the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e71ba03",
   "metadata": {},
   "source": [
    "# 5. Split the data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791723b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = weather.drop(['Apparent Temperature (C)'],axis=1)\n",
    "y = weather['Apparent Temperature (C)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a382909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd6a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train=X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d98e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c84cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81325a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dccd8c6",
   "metadata": {},
   "source": [
    "## Scaling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76879f22",
   "metadata": {},
   "source": [
    "את הנירמול לא נעשה על משתנים קטגרויאליים ושמיים שעשינו עליהם כבר encoding  \n",
    ",כי אין אפשרות להשוות\n",
    "ניצור גאטא פריים חדש מנורמל\n",
    "את הויזואליצזיה של הדאטא נעשה על הדאטא פריים המקורי, הלא מנורמל, כדי שנראה את המידע בצורה ברורה ונראה מה המספרים מייצגים"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9636f0a5",
   "metadata": {},
   "source": [
    "we will do the scaling only on numeric variables i.e not on the categorial . \n",
    "we will creaze a normalized dataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d95db0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.head()\n",
    "# delete presure , day month weekday ...\n",
    "#percip type and summary are catagorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f3fd45",
   "metadata": {},
   "source": [
    "*we are scaling only the numrical features, i.e , the features we didn't encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2048347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4da1724",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_standard = StandardScaler()\n",
    "scaler_MinMax = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14740b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_standardized = X_train.copy()\n",
    "X_test_standardized = X_test.copy()\n",
    "X_train_normalized = X_train.copy()\n",
    "X_test_normalized = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f664a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [\"Temperature (C)\",\"Humidity\",\"Wind Speed (km/h)\",\"Visibility (km)\",\"month\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2741d90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization:\n",
    "scaler_standard.fit(X_train[numerical_features])\n",
    "X_train_standardized[numerical_features] = scaler_standard.transform(X_train_standardized[numerical_features])\n",
    "\n",
    "# the scaling is with the the same fitted scaler (by the train data)\n",
    "#only transform on the test data\n",
    "X_test_standardized[numerical_features] = scaler_standard.transform(X_test_standardized[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833de946",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('note: the mean is 0 and std is 1')\n",
    "X_train_standardized.describe()[numerical_features].iloc[[1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce6ca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization:\n",
    "scaler_MinMax.fit(X_train[numerical_features])\n",
    "X_train_normalized[numerical_features] = scaler_MinMax.transform(X_train_normalized[numerical_features])\n",
    "\n",
    "# the scaling is with the the same fitted scaler (by the train data)\n",
    "#only transform on the test data\n",
    "X_test_normalized[numerical_features] = scaler_MinMax.transform(X_test_normalized[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65643176",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('note: the mean is 0 and std is 1')\n",
    "X_train_standardized.describe()[numerical_features].iloc[[1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789db6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scale=X_train.copy()\n",
    "y_train_scale=y_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f7d4b4",
   "metadata": {},
   "source": [
    "deleting the encoded variables (categorials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cb6ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X_train_scale['summary']\n",
    "# del X_train_scale['precip_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dbaa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb5e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling= MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070122ef",
   "metadata": {},
   "source": [
    "*on the train set -fit and transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a271b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scaling.fit_transform(X_train_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a245d60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arr_y_train=np.array(y_train_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ef504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling.fit_transform(arr_y_train.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70d4c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arr_x_test=np.array(X_train_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c647d0a",
   "metadata": {},
   "source": [
    "*on the test set -transform only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2f967d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scaling.transform(arr_x_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7d4b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arr_y_test=np.array(y_train_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eca243",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scaling.transform(arr_y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e4e705",
   "metadata": {},
   "source": [
    "## dealing with imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5806a2",
   "metadata": {},
   "source": [
    "*** in this part we do not touch the test set!\n",
    " \n",
    " \n",
    " we will only use the test set for the dummy model , and after the cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c2c479",
   "metadata": {},
   "source": [
    "the data is imbalanced as we can see from the histogram below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaea0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39791e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(weather, range=(1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c571e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram \n",
    "# from random import sample\n",
    "# data = sample(range(1, 1000), 100)\n",
    "plt.hist(train) # see if i can change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803fe03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram \n",
    "plt.hist(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844a1f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scale= X_train_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c620aa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_scale = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092740b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c232b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "\n",
    "# summarize class distribution\n",
    "counter = Counter(y_train)\n",
    "print(counter)\n",
    "\n",
    "oversample = SMOTE()\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "counter = Counter(y_train)\n",
    "print(counter)\n",
    "\n",
    "# scatter plot of examples by class label\n",
    "for label, _ in counter.items():\n",
    "    row_ix = where(y_train == label)[0]\n",
    "    pyplot.scatter(X_train[row_ix, 0], X_train[row_ix, 1], label=str(label))\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53077ba3",
   "metadata": {},
   "source": [
    "## dummy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceed314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569cce37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dummy_regr = DummyRegressor(strategy=\"mean\")\n",
    "dummy_regr.fit(X_train, y_train)\n",
    "R2_score = dummy_regr.score(X_test, y_test)\n",
    "y_predict = dummy_regr.predict(X_test)\n",
    "mae = MAE(y_test, y_predict)\n",
    "rmse= mean_squared_error(y_test, y_predict, squared=False)\n",
    "\n",
    "\n",
    "print ('The dummy model have a root mean squared error of '+ str(rmse) )\n",
    "\n",
    "# errorsRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b77b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('The dummy model have a R2 score of ' + str(R2_score)[:6] + \" as expected (around 0), and mean absolute error of \" + str(mae)[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fa1fb2",
   "metadata": {},
   "source": [
    "# The dummy model have a R2 score of -7.151 as expected (around 0), and mean absolute error of 9.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cddfb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_regr = DummyRegressor(strategy=\"mean\")\n",
    "# dummy_regr.fit(X_train, y_train)\n",
    "# dummy_regr.predict(X_train, y_train)\n",
    "# dummy_regr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbf4e92",
   "metadata": {},
   "source": [
    "my dummy model\n",
    "\n",
    "the mean of the Apparent Temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19589233",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=weather['Apparent Temperature (C)'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a98f23b",
   "metadata": {},
   "source": [
    "# comparing different Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f52b4c8",
   "metadata": {},
   "source": [
    "*cross validation allows us to compare different machine learning methods and get a sense of how well they will work in practice. the advantage here, is that it uses different blocks of data for train and test, and by that, \"prepare\" the model in the best way to predict outcome for new data  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c3cb6",
   "metadata": {},
   "source": [
    " # Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe4b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144591f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be16941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4604b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "R2_scores_standardized = cross_val_score(LR, X_train_standardized, y_train, cv=kf)\n",
    "y_predict_standardized = cross_val_predict(LR, X_train_standardized, y_train, cv=kf)\n",
    "mae_standarsized = MAE(y_train, y_predict_standardized)\n",
    "\n",
    "R2_scores_normalized = cross_val_score(LR, X_train_normalized, y_train, cv=kf)\n",
    "y_predict_normalized = cross_val_predict(LR, X_train_normalized, y_train, cv=kf)\n",
    "mae_normalized = MAE(y_train, y_predict_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bde279",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2)\n",
    "((ax1, ax2)) = axes\n",
    "\n",
    "y_predicted = cross_val_predict(LR, X_train_standardized, y_train, cv=kf)\n",
    "ax1.scatter(y_train, y_predicted, alpha=0.3, color='orange')\n",
    "ax1.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k--', lw=4)\n",
    "ax1.set_xlabel('Actual')\n",
    "ax1.set_ylabel('Predicted')\n",
    "ax1.set_title('standardized:')\n",
    "\n",
    "y_predicted = cross_val_predict(LR, X_train_normalized, y_train, cv=kf)\n",
    "ax2.scatter(y_train, y_predicted, alpha=0.3, color='red')\n",
    "ax2.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k--', lw=4)\n",
    "ax2.set_xlabel('Actual')\n",
    "ax2.set_ylabel('Predicted')\n",
    "ax2.set_title('normalized:')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabb72a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standadized train set cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6bbc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the scores of cross validation are:\")\n",
    "print(R2_scores_standardized)\n",
    "print()\n",
    "print(\"mean R2 is: \" + str(R2_scores_standardized.mean())[:5] + \" with std of  \" + str(R2_scores_standardized.std())[:5] + \" and MAE of \" + str(mae_standarsized)[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c92f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalized train set cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20454da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the scores of cross validation are:\")\n",
    "print(R2_scores_normalized)\n",
    "print()\n",
    "print(\"mean R2 is: \" + str(R2_scores_normalized.mean())[:5] + \" with std of  \" + str(R2_scores_normalized.std())[:5] + \" and MAE of \" + str(mae_normalized)[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d17fa3e",
   "metadata": {},
   "source": [
    "although the results are the same with normalized and standardized,\n",
    "we can see below that the feature values are definetly different "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8510b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffdcb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fe6241",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aa7ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b7b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444afded",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1433d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d651fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_scores_standardized = cross_val_score(regr, X_train_standardized, y_train, cv=kf)\n",
    "y_predict_standardized = cross_val_predict(regr, X_train_standardized, y_train, cv=kf)\n",
    "mae_standarsized = MAE(y_train, y_predict_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed84c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_scores_normalized = cross_val_score(regr, X_train_normalized, y_train, cv=kf)\n",
    "y_predict_normalized = cross_val_predict(regr, X_train_normalized, y_train, cv=kf)\n",
    "mae_normalized = MAE(y_train, y_predict_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6923fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the scores of cross validation are:\")\n",
    "print(R2_scores_standardized)\n",
    "print()\n",
    "print(\"mean R2 is: \" + str(R2_scores_standardized.mean())[:5] + \" with std of  \" + str(R2_scores_standardized.std())[:5] + \" and MAE of \" + str(mae_standarsized)[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08da456f",
   "metadata": {},
   "source": [
    "# Keras Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d8d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2062d623",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf5b011",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8722ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3a8335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5764a239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Also, ADAM optimization algorithm is used for optimizing loss function (Mean squared error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd809617",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.metrics.RootMeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73d7cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(11,activation='relu'))\n",
    "model.add(Dense(11,activation='relu'))\n",
    "model.add(Dense(11,activation='relu'))\n",
    "model.add(Dense(11,activation='relu'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae',tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724f6281",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece00c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train).astype(np.float32)\n",
    "y_train = np.asarray(y_train).astype(np.float32)\n",
    "X_test= np.asarray(X_test).astype(np.float32)\n",
    "y_test= np.asarray(y_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f582cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=X_train,y=y_train,\n",
    "          validation_data=(X_test,y_test),\n",
    "          batch_size=128,epochs=400)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081ace4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b7e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history.history['val_mse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa0c937",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history.history['val_mae']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb029bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history.history['val_root_mean_squared_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af065925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot metrics\n",
    "pyplot.plot(loss_df ['mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b8973",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(loss_df ['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571790a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(loss_df ['root_mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdde3f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(loss_df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb03159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41ba7faa",
   "metadata": {},
   "source": [
    "# hyperparameter tuning \n",
    "I will try to increase the R2 score and the MAE of the Random Forest Regressor model by choosing the best hyperparams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f219e15e",
   "metadata": {},
   "source": [
    "## random search "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d843af",
   "metadata": {},
   "source": [
    "With small data sets and lots of resources, Grid Search will produce accurate results. However, with large data sets, the high dimensions will greatly slow down computation time and be very costly. Therefore, we chose to use random search for "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90eec10",
   "metadata": {},
   "source": [
    "random search requires two arguments. The first is the model that you are optimizing. This is an instance of the model with values of hyperparameters set that you want to optimize. \n",
    "The second is the search space:\n",
    "This is defined as a dictionary where the names are the hyperparameter arguments to the model and the values are discrete values or a distribution of values to sample in the case of a random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "id": "161fecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.stats import loguniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "id": "8feb7a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "id": "d9bacc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Ridge()\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['svd', 'cholesky', 'lsqr', 'sag']\n",
    "space['alpha'] = loguniform(1e-5, 100)\n",
    "space['fit_intercept'] = [True, False]\n",
    "space['normalize'] = [True, False]\n",
    "\n",
    "# define search\n",
    "# pattern - search = GridSearchCV(model, space)\n",
    "search = RandomizedSearchCV(model, space, n_iter=500, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "id": "b76a2ca5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-950-1e93d33b55db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# execute search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_normalized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# summarize result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best Score: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best Hyperparameters: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1765\u001b[0m         \u001b[1;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1766\u001b[1;33m         evaluate_candidates(\n\u001b[0m\u001b[0;32m   1767\u001b[0m             ParameterSampler(\n\u001b[0;32m   1768\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# execute search\n",
    "result = search.fit(X_train_normalized, y_train)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af024224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
